{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import regex\n",
    "\n",
    "import nltk\n",
    "from nltk import SnowballStemmer\n",
    "snowball = SnowballStemmer(language=\"russian\")\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list([word for word in stopwords.words('russian') if not word in ['без','не','нет']])\n",
    "stop_words=set(stop_words)\n",
    "stopword = stop_words.union({'недел', 'недель', 'беремен', 'витамин','тип', 'феврал','февраль','степен', 'посл', 'ст', 'ог', 'оа', 'мед', 'тел', 'год', 'брак', 'зарегистрирова', 'ммртст', 'уд', 'мин', 'мм', 'рт', 'мкг', 'мг', 'кг', 'ад', 'сутк', 'мес', 'род', 'вес', 'рожден', 'гр', 'январ', 'октябр','январь', 'октябрь', 'мат', 'мать', 'отец', 'бабушк', 'бабушка','мам', 'мама','сестр', 'дедушк','сестра', 'дедушка',  'брат', 'гб', 'отц', 'пап', 'дед', 'дяд','дядя', 'ма', 'папин', 'дедшк', 'племянник', 'бабаушк', 'сын', 'доч','дочь', 'бабк', 'декабрь', 'март','апрел','апрель','май','июн','июл','июнь','июль','август','сентябр','октябр','ноябр','сентябрь','октябрь','ноябрь','декабр', 'нед', 'годас', 'ден'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    tweet = str(tweet)\n",
    "    tweet = regex.sub(r'\\p{P}(?!\\d)',' ',tweet) #все символы пунктуации\n",
    "    tweet = re.sub('\\d+', ' ', tweet)#цифры\n",
    "    tweet = re.sub('\\+', ' ', tweet)#специальные символы\n",
    "    tweet = re.sub('\\r', ' ', tweet)#специальные символы\n",
    "    tweet = re.sub('\\n', ' ', tweet)#специальные символы\n",
    "    tweet = re.sub('\\s\\S\\s', ' ', tweet) #один символ\n",
    "    tweet = regex.sub(r'\\s+',' ', tweet) #увеличенное количество пробельных символов\n",
    "    return tweet \n",
    "\n",
    "def clean(x):\n",
    "    x = x.split(' ')\n",
    "    x = [morph.parse(k)[0].normal_form for k in x] #Лемматизация\n",
    "    x = [snowball.stem(k) for k in x]\n",
    "    x = ' '.join([k for k in x if k not in stopword]) #удаление стоп-слов\n",
    "    return x\n",
    "\n",
    "def data_preprocessing(x): \n",
    "    #выравнивание регистра\n",
    "    x = str(x).lower()\n",
    "    x = clean_tweet(x)\n",
    "    x = clean(x)\n",
    "    return x\n",
    "\n",
    "def clean_tweet1(tweet):\n",
    "    tweet = str(tweet)\n",
    "    tweet = regex.sub(r'\\p{P}(?!\\d)',' ',tweet) #все символы пунктуации\n",
    "    tweet = re.sub('\\)', ' ', tweet)#специальные символы\n",
    "    tweet = re.sub('\\s\\d+\\s', ' ', tweet)#цифры\n",
    "    tweet = re.sub('\\+', ' ', tweet)#специальные символы\n",
    "    tweet = re.sub('\\r', ' ', tweet)#специальные символы\n",
    "    tweet = re.sub('\\n', ' ', tweet)#специальные символы\n",
    "    tweet = re.sub('\\s\\S\\s', ' ', tweet) #один символ\n",
    "    tweet = regex.sub(r'\\s+',' ', tweet) #все пробельные символы\n",
    "    return tweet \n",
    "\n",
    "def data_preprocessing1(x): \n",
    "    #выравнивание регистра\n",
    "    x = str(x).lower()\n",
    "    x = clean_tweet1(x)\n",
    "    x = clean(x)\n",
    "    return x\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=False))\n",
    "        \n",
    "def token(df, name):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df0=df.copy(deep=True)\n",
    "    for i in range (len(df0[name])):\n",
    "        c= (tokenizer.tokenize(df0[name][i]))\n",
    "        for j in range (len(c)):\n",
    "            if c[j]=='не':\n",
    "                if j+1<len(c):\n",
    "                    c[j]='не_'+c[j+1]\n",
    "                    c[j+1]=''\n",
    "                else:\n",
    "                    c[j]=''\n",
    "            elif c[j]=='без':\n",
    "                if j+1<len(c):\n",
    "                    c[j]='без_'+c[j+1]\n",
    "                    c[j+1]=''\n",
    "                else:\n",
    "                    c[j]=''\n",
    "            if c[j]=='отрицательн':\n",
    "                if j!=0:\n",
    "                    c[j]=c[j-1]+'_отрицательн'\n",
    "                    c[j-1]=''   \n",
    "        df0[name][i]=' '.join([k for k in c if k != ''])\n",
    "    return(df0)\n",
    "        \n",
    "def norm(df, name):\n",
    "    s=['не_быт', 'отрица', 'нет', 'не_отягот', 'без_особен','не_имет', 'вредн', 'вред', 'привычк', 'превычек', 'проф вредност отриц','проф вредност отр', 'ипроф вредност отриц', 'не_имет', 'вред привычк отриц', 'не_кур', 'не_пит']\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df0=df.copy(deep=True)\n",
    "    for i in range (len(df0[name])):\n",
    "        c= (tokenizer.tokenize(df0[name][i]))\n",
    "        for j in range (len(c)):\n",
    "            if c[j] in s:\n",
    "                c[j]=''\n",
    "        df0[name][i]=' '.join([k for k in c if k != ''])\n",
    "    return(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/1_type.csv', delimiter=',') #считывание записей \n",
    "del df['Unnamed: 0']\n",
    "df = df.dropna(axis='index', how='any', subset=['diagnos'])\n",
    "df = df.fillna('')\n",
    "df=df.reset_index(drop=True)\n",
    "df.rename(columns = {'course ':'course'}, inplace = True)\n",
    "df=df.drop_duplicates(keep='first')\n",
    "\n",
    "df = df.loc[df['weeks'] > 0] #очистка от данные с подготовкой к беременности\n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Препроцессинг данных\n",
    "\n",
    "for name in ['value', 'diagnos', 'com','ill', 'heredity', 'habits', 'gynecology', 'inspection', 'husband', 'course', 'pills', 'previous','fetus']:\n",
    "    df[name] = df[name].apply(data_preprocessing) #очистка от пукнтуации, стоп-слов, лемматизация\n",
    "    df = token(df,name) #токенизация\n",
    "    df = norm(df,name)\n",
    "df['recommendations'] = df['recommendations'].apply(data_preprocessing1)\n",
    "df = token(df,'recommendations')\n",
    "df = norm(df,'recommendations')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определение триместра\n",
    "\n",
    "df['trim']=0\n",
    "for i in range(len(df)):\n",
    "    if df['weeks'][i] < 14:\n",
    "        df['trim'][i]=1\n",
    "    if ((df['weeks'][i] >= 14)& (df['weeks'][i] <= 27)):\n",
    "        df['trim'][i]=2\n",
    "    if df['weeks'][i] > 27:\n",
    "        df['trim'][i]=3\n",
    "for i in range(len(df)):\n",
    "    if df['age'][i] < 18:\n",
    "        df['age'][i]=1\n",
    "    if ((df['age'][i] >= 18)& (df['age'][i] <= 40)):\n",
    "        df['age'][i]=2\n",
    "    if df['age'][i] > 40:\n",
    "        df['age'][i]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Группировка призноков\n",
    "\n",
    "df['fir']=df['value']+' '+df['gynecology']+' '+df['inspection']+' '+df['fetus']+' '+df['course'] \n",
    "df['sec']=df['heredity']+' '+df['husband']+' '+df['habits'] \n",
    "df['thr']=df['previous']+' '+df['recommendations']+' '+df['pills']+' '+df['ill']\n",
    "del df['husband']\n",
    "del df['course']\n",
    "del df['previous']\n",
    "del df['fetus']\n",
    "del df['value']\n",
    "del df['ill']\n",
    "del df['heredity']\n",
    "del df['habits']\n",
    "del df['gynecology']\n",
    "del df['inspection']\n",
    "del df['pills']\n",
    "del df['action_id']\n",
    "del df['id']\n",
    "del df['recommendations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохранение очищенных данных\n",
    "\n",
    "df.to_csv('data/1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
